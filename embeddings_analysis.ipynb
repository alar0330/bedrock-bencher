{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Analysis\n",
    "\n",
    "Examples for loading and analyzing embedding runs, including similarity calculations and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from bedrock_benchmark.core import BenchmarkCore\n",
    "from bedrock_benchmark.storage import StorageManager\n",
    "\n",
    "# Initialize\n",
    "storage_manager = StorageManager('./experiments')\n",
    "benchmark_core = BenchmarkCore(storage_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Embedding Experiments and Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all experiments\n",
    "experiments = benchmark_core.list_experiments()\n",
    "for exp in experiments:\n",
    "    print(f\"{exp.id}: {exp.name} ({len(benchmark_core.list_runs(exp.id))} runs)\")\n",
    "\n",
    "# Focus on embedding experiments\n",
    "embedding_experiments = [exp for exp in experiments if 'embedding' in exp.id.lower() or 'embed' in exp.name.lower()]\n",
    "\n",
    "if embedding_experiments:\n",
    "    experiment_id = embedding_experiments[0].id\n",
    "    runs = benchmark_core.list_runs(experiment_id)\n",
    "    print(f\"\\nRuns in {experiment_id}:\")\n",
    "    for run_id in runs:\n",
    "        summary = benchmark_core.get_run_summary(run_id)\n",
    "        print(f\"  {run_id}: {summary['model_id']} - {summary['total_responses']} embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embedding Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first embedding run\n",
    "if runs:\n",
    "    run_id = runs[0]\n",
    "    \n",
    "    # Get run configuration to extract dataset path\n",
    "    run_config = storage_manager.get_run_config(run_id)\n",
    "    \n",
    "    if run_config and run_config.dataset_path:\n",
    "        dataset_path = run_config.dataset_path\n",
    "        print(f\"Dataset path from config: {dataset_path}\")\n",
    "        print(f\"Model: {run_config.model_id}\")\n",
    "        print(f\"Model params: {run_config.model_params}\")\n",
    "    \n",
    "    # Export run to get embeddings\n",
    "    df = benchmark_core.export_run_to_dataframe(run_id)\n",
    "    \n",
    "    print(f\"\\nLoaded run {run_id}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Show first few rows (without showing full embeddings)\n",
    "    display(df[['run_id', 'item_id', 'model_id', 'latency_ms']].head())\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"\\nAverage latency: {df['latency_ms'].mean():.2f}ms\")\n",
    "    print(f\"Embedding dimension: {len(df['embedding'].iloc[0]) if 'embedding' in df.columns else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Embeddings as NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings to numpy array for analysis\n",
    "if 'embedding' in df.columns:\n",
    "    embeddings = np.array(df['embedding'].tolist())\n",
    "    print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "    print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "    print(f\"Number of embeddings: {embeddings.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Cosine Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pairwise cosine similarity\n",
    "if 'embeddings' in locals():\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    print(f\"Similarity matrix shape: {similarity_matrix.shape}\")\n",
    "    print(f\"\\nSimilarity statistics:\")\n",
    "    print(f\"  Mean similarity: {similarity_matrix.mean():.4f}\")\n",
    "    print(f\"  Std similarity: {similarity_matrix.std():.4f}\")\n",
    "    print(f\"  Min similarity: {similarity_matrix.min():.4f}\")\n",
    "    print(f\"  Max similarity: {similarity_matrix.max():.4f}\")\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    similarity_df = pd.DataFrame(\n",
    "        similarity_matrix,\n",
    "        index=df['item_id'].values,\n",
    "        columns=df['item_id'].values\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSimilarity matrix (first 5x5):\")\n",
    "    display(similarity_df.iloc[:5, :5].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of similarity matrix\n",
    "if 'similarity_matrix' in locals():\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        similarity_df,\n",
    "        cmap='coolwarm',\n",
    "        center=0.5,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"shrink\": 0.8}\n",
    "    )\n",
    "    plt.title('Cosine Similarity Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Most Similar Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar pairs (excluding self-similarity)\n",
    "if 'similarity_matrix' in locals():\n",
    "    # Set diagonal to -1 to exclude self-similarity\n",
    "    sim_no_diag = similarity_matrix.copy()\n",
    "    np.fill_diagonal(sim_no_diag, -1)\n",
    "    \n",
    "    # Find top 5 most similar pairs\n",
    "    print(\"Top 5 most similar item pairs:\\n\")\n",
    "    for i in range(5):\n",
    "        max_idx = np.unravel_index(sim_no_diag.argmax(), sim_no_diag.shape)\n",
    "        similarity = sim_no_diag[max_idx]\n",
    "        item1 = df['item_id'].iloc[max_idx[0]]\n",
    "        item2 = df['item_id'].iloc[max_idx[1]]\n",
    "        \n",
    "        print(f\"{i+1}. {item1} <-> {item2}: {similarity:.4f}\")\n",
    "        \n",
    "        # Set to -1 to find next highest\n",
    "        sim_no_diag[max_idx] = -1\n",
    "        sim_no_diag[max_idx[1], max_idx[0]] = -1  # Also set symmetric entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Visualization with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce embeddings to 2D for visualization\n",
    "if 'embeddings' in locals() and len(embeddings) > 3:\n",
    "    # Use t-SNE for dimensionality reduction\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(embeddings)-1))\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scatter = plt.scatter(\n",
    "        embeddings_2d[:, 0],\n",
    "        embeddings_2d[:, 1],\n",
    "        c=range(len(embeddings)),\n",
    "        cmap='viridis',\n",
    "        s=100,\n",
    "        alpha=0.6\n",
    "    )\n",
    "    \n",
    "    # Add labels\n",
    "    for i, item_id in enumerate(df['item_id']):\n",
    "        plt.annotate(\n",
    "            item_id,\n",
    "            (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "            xytext=(5, 5),\n",
    "            textcoords='offset points',\n",
    "            fontsize=8,\n",
    "            alpha=0.7\n",
    "        )\n",
    "    \n",
    "    plt.colorbar(scatter, label='Item Index')\n",
    "    plt.title('Embedding Space Visualization (t-SNE)')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Need at least 4 embeddings for t-SNE visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Multiple Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple runs for comparison\n",
    "if len(runs) >= 2:\n",
    "    comparison_data = []\n",
    "    \n",
    "    for run_id in runs[:3]:  # Compare up to 3 runs\n",
    "        df_run = benchmark_core.export_run_to_dataframe(run_id)\n",
    "        run_config = storage_manager.get_run_config(run_id)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'run_id': run_id,\n",
    "            'model': run_config.model_id if run_config else 'Unknown',\n",
    "            'num_embeddings': len(df_run),\n",
    "            'avg_latency_ms': df_run['latency_ms'].mean(),\n",
    "            'embedding_dim': len(df_run['embedding'].iloc[0]) if 'embedding' in df_run.columns else 0\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(\"\\nModel Comparison:\")\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Visualize latency comparison\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(range(len(comparison_df)), comparison_df['avg_latency_ms'])\n",
    "    plt.xticks(range(len(comparison_df)), comparison_df['model'], rotation=45, ha='right')\n",
    "    plt.ylabel('Average Latency (ms)')\n",
    "    plt.title('Embedding Generation Latency by Model')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Only {len(runs)} run available - need 2+ for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find most similar items to a query item\n",
    "if 'similarity_matrix' in locals() and len(df) > 0:\n",
    "    query_idx = 0  # Use first item as query\n",
    "    query_item = df['item_id'].iloc[query_idx]\n",
    "    \n",
    "    # Get similarities to query\n",
    "    similarities = similarity_matrix[query_idx]\n",
    "    \n",
    "    # Sort by similarity (excluding self)\n",
    "    similar_indices = np.argsort(similarities)[::-1][1:6]  # Top 5, excluding self\n",
    "    \n",
    "    print(f\"Query item: {query_item}\")\n",
    "    print(f\"\\nTop 5 most similar items:\\n\")\n",
    "    \n",
    "    for rank, idx in enumerate(similar_indices, 1):\n",
    "        similar_item = df['item_id'].iloc[idx]\n",
    "        similarity = similarities[idx]\n",
    "        print(f\"{rank}. {similar_item}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings and similarity matrix\n",
    "if 'df' in locals():\n",
    "    # Save embeddings DataFrame\n",
    "    df.to_csv('embeddings_data.csv', index=False)\n",
    "    print(\"Saved embeddings to: embeddings_data.csv\")\n",
    "\n",
    "if 'similarity_df' in locals():\n",
    "    # Save similarity matrix\n",
    "    similarity_df.to_csv('similarity_matrix.csv')\n",
    "    print(\"Saved similarity matrix to: similarity_matrix.csv\")\n",
    "\n",
    "if 'embeddings' in locals():\n",
    "    # Save embeddings as numpy array\n",
    "    np.save('embeddings.npy', embeddings)\n",
    "    print(\"Saved embeddings array to: embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock-benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
